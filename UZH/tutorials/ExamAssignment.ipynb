{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c0d600b6-5377-4c5c-a011-9b2e61a4018c",
      "metadata": {
        "id": "c0d600b6-5377-4c5c-a011-9b2e61a4018c"
      },
      "source": [
        "# Galaxy Classification, Anomaly Detection, Autoencoder & VAE (Keras)\n",
        "This notebook uses the Galaxy10 DECaLS dataset (astronomical galaxy images) for:\n",
        "\n",
        "1. Data loading & splitting, defining an anomaly class  \n",
        "2. CNN classifier + ROC curves & confusion matrices  \n",
        "3. Convolutional autoencoder for anomaly detection  \n",
        "4. Variational autoencoder (VAE) + galaxy generation\n",
        "\n",
        "Dataset: Galaxy10 DECaLS (HDF5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0405a22e-6256-41bf-b1a4-8ab6b8dec0f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0405a22e-6256-41bf-b1a4-8ab6b8dec0f5",
        "outputId": "95ae73d5-2320-457a-8432-da955c806a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
            "Logical GPU devices: []\n",
            "GPU device name: \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"Physical devices:\", tf.config.list_physical_devices())\n",
        "print(\"Logical GPU devices:\", tf.config.list_logical_devices('GPU'))\n",
        "print(\"GPU device name:\", tf.test.gpu_device_name())\n",
        "\n",
        "from tensorflow import keras # (changed) sticking to tf.keras\n",
        "from tensorflow.keras import layers, ops, Model, random, regularizers, optimizers, models\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import random as py_random\n",
        "\n",
        "SEED = 42  # for reproducibility\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "py_random.seed(SEED)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b69305b-ce16-4539-8bf9-fb7c4e4ebeb1",
      "metadata": {
        "id": "5b69305b-ce16-4539-8bf9-fb7c4e4ebeb1"
      },
      "source": [
        "## 1. Download the dataset, inspect classes, create anomaly split\n",
        "\n",
        "Steps:\n",
        "- Download `Galaxy10_DECals_64.h5`\n",
        "- Load images and labels with `h5py`\n",
        "- Inspect shape and class distribution\n",
        "- Remove class 0 and store it as the anomaly dataset\n",
        "- Split remaining (standard) data into train (50%), val (25%), test (25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6b894ed2-1915-47eb-b716-5246f25e926a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b894ed2-1915-47eb-b716-5246f25e926a",
        "outputId": "ab38ce51-81fb-44f9-db90-d00a7708d04f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-09 16:41:19--  https://cernbox.cern.ch/remote.php/dav/public-files/RyWK8CBk2yqKR0b/Galaxy10_DECals_64.h5\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 128.142.53.35, 128.142.53.28, 137.138.120.151, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|128.142.53.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 159140118 (152M) [application/octet-stream]\n",
            "Saving to: ‘Galaxy10_DECals_64.h5’\n",
            "\n",
            "Galaxy10_DECals_64.   5%[>                   ]   8.27M  95.0KB/s    eta 3m 38s ^C\n",
            "Downloaded to: ./Galaxy10_DECals_64.h5\n"
          ]
        }
      ],
      "source": [
        "# Download Galaxy10 DECaLS (HDF5)\n",
        "! rm ./Galaxy10_DECals_64.h5\n",
        "! wget https://cernbox.cern.ch/remote.php/dav/public-files/RyWK8CBk2yqKR0b/Galaxy10_DECals_64.h5\n",
        "data_path = \"./Galaxy10_DECals_64.h5\"\n",
        "\n",
        "print(\"Downloaded to:\", data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3aae2712-8c0f-4fd3-8dc8-7bfa1a024d47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "3aae2712-8c0f-4fd3-8dc8-7bfa1a024d47",
        "outputId": "7ca9b87c-0e71-4ece-c536-2da5b1471a18"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Unable to synchronously open file (truncated file: eof = 1801408, sblock->base_addr = 0, stored_eof = 159140118)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3469028965.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load images and labels using h5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# shape (17736, 64, 64, 3) (changed from 256 to 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# shape (17736,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, track_times, **kwds)\u001b[0m\n\u001b[1;32m    564\u001b[0m                                  \u001b[0mfs_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  fs_threshold=fs_threshold, fs_page_size=fs_page_size)\n\u001b[0;32m--> 566\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to synchronously open file (truncated file: eof = 1801408, sblock->base_addr = 0, stored_eof = 159140118)"
          ]
        }
      ],
      "source": [
        "# Load images and labels using h5py\n",
        "with h5py.File(data_path, \"r\") as f:\n",
        "    images = np.array(f[\"images\"])   # shape (17736, 64, 64, 3) (changed from 256 to 64)\n",
        "    labels = np.array(f[\"ans\"])      # shape (17736,)\n",
        "\n",
        "#  normalize pixels in [0,1]\n",
        "images = images.astype(\"float32\") / 255.0 # (Keras works more efficiently and uses less memory with float32)\n",
        "\n",
        "\n",
        "print(\"Images shape:\", images.shape)\n",
        "print(\"Labels shape:\", labels.shape, \"dtype:\", labels.dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84923652-4b90-45e2-bbd7-ce076c3fc0f1",
      "metadata": {
        "id": "84923652-4b90-45e2-bbd7-ce076c3fc0f1"
      },
      "outputs": [],
      "source": [
        "# Class names from the Galaxy10 DECaLS documentation\n",
        "class_names = {\n",
        "    0: \"Disturbed Galaxies\",\n",
        "    1: \"Merging Galaxies\",\n",
        "    2: \"Round Smooth Galaxies\",\n",
        "    3: \"In-between Round Smooth Galaxies\",\n",
        "    4: \"Cigar Shaped Smooth Galaxies\",  # will be 'anomaly'\n",
        "    5: \"Barred Spiral Galaxies\",\n",
        "    6: \"Unbarred Tight Spiral Galaxies\",\n",
        "    7: \"Unbarred Loose Spiral Galaxies\",\n",
        "    8: \"Edge-on Galaxies without Bulge\",\n",
        "    9: \"Edge-on Galaxies with Bulge\"\n",
        "}\n",
        "\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "print(\"Class distribution:\")\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"Class {u} ({class_names[u]}): {c}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f0b298b-693f-4c23-a289-d4af98b077e5",
      "metadata": {
        "id": "7f0b298b-693f-4c23-a289-d4af98b077e5"
      },
      "outputs": [],
      "source": [
        "# Show a grid of sample images from different classes\n",
        "def show_examples(images, labels, class_names, n_rows=2, n_cols=5):\n",
        "    plt.figure(figsize=(3*n_cols, 3*n_rows))\n",
        "    indices = np.random.choice(len(images), size=n_rows*n_cols, replace=False)\n",
        "    for i, idx in enumerate(indices):\n",
        "        plt.subplot(n_rows, n_cols, i+1)\n",
        "        plt.imshow(images[idx])\n",
        "        plt.title(f\"Class {labels[idx]}:\\n{class_names[int(labels[idx])]}\", fontsize=8)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_examples(images, labels, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7314b848-78d6-4023-97c6-dd194491877e",
      "metadata": {
        "id": "7314b848-78d6-4023-97c6-dd194491877e"
      },
      "outputs": [],
      "source": [
        "# Create anomaly dataset: all class 0 images (changed to 4 for now)\n",
        "ANOMALY_CLASS = 4\n",
        "\n",
        "anomaly_mask = (labels == ANOMALY_CLASS)\n",
        "standard_mask = ~anomaly_mask\n",
        "\n",
        "anom_images = images[anomaly_mask]\n",
        "anom_labels = labels[anomaly_mask]  # all 0, but we keep them for bookkeeping (changed to 4)\n",
        "\n",
        "std_images = images[standard_mask]\n",
        "std_labels_original = labels[standard_mask]\n",
        "\n",
        "print(\"Standard images:\", std_images.shape)\n",
        "print(\"Anomaly images:\", anom_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f12ea4c4-f9a4-4d63-9f5f-ac6aa87c9a57",
      "metadata": {
        "id": "f12ea4c4-f9a4-4d63-9f5f-ac6aa87c9a57"
      },
      "outputs": [],
      "source": [
        "# For training, remap standard labels from {0,1,2,3,5,6,7,8,9} -> {0,...,8}\n",
        "unique_std_classes = sorted(np.unique(std_labels_original))\n",
        "print(\"Standard classes (original indices):\", unique_std_classes)\n",
        "\n",
        "# Create mapping dict\n",
        "label_map = {original: new for new, original in enumerate(unique_std_classes)}\n",
        "inv_label_map = {v: k for k, v in label_map.items()}\n",
        "\n",
        "print(\"Label map (original -> new):\", label_map)\n",
        "\n",
        "std_labels = np.vectorize(label_map.get)(std_labels_original)\n",
        "print(\"Remapped standard labels min/max:\", std_labels.min(), std_labels.max())\n",
        "n_classes = len(unique_std_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b0e42f-90ab-4326-ace5-36658b3ccf3f",
      "metadata": {
        "id": "a8b0e42f-90ab-4326-ace5-36658b3ccf3f"
      },
      "outputs": [],
      "source": [
        "# Split standard data: 50% train, 25% val, 25% test\n",
        "\n",
        "# First split: train (50%) and temp (50%)\n",
        "X_train_std, X_temp_std, y_train_std, y_temp_std = train_test_split(\n",
        "    std_images,\n",
        "    std_labels,\n",
        "    test_size=0.5,\n",
        "    stratify=std_labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Second split: temp into val (25%) and test (25%) of full standard data\n",
        "X_val_std, X_test_std, y_val_std, y_test_std = train_test_split(\n",
        "    X_temp_std,\n",
        "    y_temp_std,\n",
        "    test_size=0.5,\n",
        "    stratify=y_temp_std,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train standard:\", X_train_std.shape, y_train_std.shape)\n",
        "print(\"Val standard:  \", X_val_std.shape, y_val_std.shape)\n",
        "print(\"Test standard: \", X_test_std.shape, y_test_std.shape)\n",
        "del std_images, std_labels, X_temp_std, y_temp_std"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA**"
      ],
      "metadata": {
        "id": "Ml4xBSkEeWbC"
      },
      "id": "Ml4xBSkEeWbC"
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(data_path, \"r\") as f:\n",
        "    images = f[\"images\"][()]      # (N, 64, 64, 3)\n",
        "    labels = f[\"ans\"][()]         # (N,)\n",
        "    ra = f[\"ra\"][()]\n",
        "    dec = f[\"dec\"][()]\n",
        "    redshift = f[\"redshift\"][()]\n",
        "    pxscale = f[\"pxscale\"][()]"
      ],
      "metadata": {
        "id": "g4e4tMy-f8W8"
      },
      "id": "g4e4tMy-f8W8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset structure & basic stats"
      ],
      "metadata": {
        "id": "Cf2p7ZOzeZTa"
      },
      "id": "Cf2p7ZOzeZTa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic dataset overview\n",
        "N, H, W, C = images.shape\n",
        "print(f\"Number of images: {N}\")\n",
        "print(f\"Image size: {H}x{W}, channels: {C}\")\n",
        "print(f\"Images dtype: {images.dtype}, range: [{images.min():.3f}, {images.max():.3f}]\")\n",
        "print(f\"Labels shape: {labels.shape}, dtype: {labels.dtype}\")\n",
        "\n",
        "# Per-channel statistics\n",
        "channel_means = images.reshape(-1, C).mean(axis=0)\n",
        "channel_stds = images.reshape(-1, C).std(axis=0)\n",
        "print(\"\\nPer-channel mean (R,G,B):\", channel_means)\n",
        "print(\"Per-channel std  (R,G,B):\", channel_stds)\n",
        "\n",
        "# Redshift NaN info\n",
        "nan_z = np.isnan(redshift).sum()\n",
        "print(f\"\\nRedshift NaNs: {nan_z} / {N}\")\n"
      ],
      "metadata": {
        "id": "QLObUBI6eXa9"
      },
      "id": "QLObUBI6eXa9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class distribution"
      ],
      "metadata": {
        "id": "zzV8Ae41fCbb"
      },
      "id": "zzV8Ae41fCbb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Class names\n",
        "class_names = {\n",
        "    0: \"Disturbed Galaxies\",\n",
        "    1: \"Merging Galaxies\",\n",
        "    2: \"Round Smooth Galaxies\",\n",
        "    3: \"In-between Round Smooth Galaxies\",\n",
        "    4: \"Cigar Shaped Smooth Galaxies\",  # anomaly for me\n",
        "    5: \"Barred Spiral Galaxies\",\n",
        "    6: \"Unbarred Tight Spiral Galaxies\",\n",
        "    7: \"Unbarred Loose Spiral Galaxies\",\n",
        "    8: \"Edge-on Galaxies without Bulge\",\n",
        "    9: \"Edge-on Galaxies with Bulge\"\n",
        "}\n",
        "\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "print(\"=== Class distribution ===\")\n",
        "for u, c in zip(unique, counts):\n",
        "    frac = c / N * 100\n",
        "    print(f\"Class {u} ({class_names[u]}): {c} samples ({frac:.2f}%)\")\n",
        "\n",
        "# Bar plot\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(unique, counts)\n",
        "plt.xticks(unique)\n",
        "plt.xlabel(\"Class label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class distribution\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IoFu6mameznV"
      },
      "id": "IoFu6mameznV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metadata distributions"
      ],
      "metadata": {
        "id": "ZcE-qSPwfD7s"
      },
      "id": "ZcE-qSPwfD7s"
    },
    {
      "cell_type": "code",
      "source": [
        "# Redshift distribution (valid values only)\n",
        "valid_z = redshift[~np.isnan(redshift)]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(valid_z, bins=40)\n",
        "plt.xlabel(\"Redshift z\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Redshift distribution (valid entries)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Pixel scale distribution\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(pxscale, bins=30)\n",
        "plt.xlabel(\"Pixel scale [arcsec/pixel]\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Pixel scale distribution\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Sky coverage\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(ra, dec, s=2)\n",
        "plt.xlabel(\"RA [deg]\")\n",
        "plt.ylabel(\"Dec [deg]\")\n",
        "plt.title(\"Sky coverage (RA vs Dec)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eTynsc38fvF5"
      },
      "id": "eTynsc38fvF5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d1cf6fb6-fcff-4e70-86ae-8e2de5d029d9",
      "metadata": {
        "id": "d1cf6fb6-fcff-4e70-86ae-8e2de5d029d9"
      },
      "source": [
        "## 2. CNN classifier + ROC curves + confusion matrices\n",
        "\n",
        "Steps:\n",
        "- Build a CNN classifier on the **standard** dataset (9 classes)\n",
        "- Train on train set, validate on val set\n",
        "- Plot training history (loss & accuracy)\n",
        "- Compute ROC curves (one-vs-rest) on the standard test set\n",
        "- Compute confusion matrix for standard test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a CNN classifier on the standard dataset (9 classes)"
      ],
      "metadata": {
        "id": "YDdoVuxxkTrX"
      },
      "id": "YDdoVuxxkTrX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f681f715-a45c-40a0-a773-b1e671b8097d",
      "metadata": {
        "id": "f681f715-a45c-40a0-a773-b1e671b8097d"
      },
      "outputs": [],
      "source": [
        "def build_simple_cnn(input_shape, n_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # --- Conv block 1 ---\n",
        "    x = layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)   # 32x32\n",
        "\n",
        "    # --- Conv block 2 ---\n",
        "    x = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)   # 16x16\n",
        "\n",
        "    # --- Conv block 3 ---\n",
        "    x = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)   # 8x8\n",
        "\n",
        "    # --- Top ---\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-3),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "input_shape = X_train_std.shape[1:]  # (64, 64, 3)\n",
        "model = build_simple_cnn(input_shape, n_classes)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train on train set, validate on val set"
      ],
      "metadata": {
        "id": "d8NLzSzdkPYB"
      },
      "id": "d8NLzSzdkPYB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the CNN\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,      # halve LR\n",
        "        patience=3,      # after 3 epochs without improvement\n",
        "        min_lr=1e-5,\n",
        "        verbose=1,\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_std, y_train_std,\n",
        "    validation_data=(X_val_std, y_val_std),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")\n"
      ],
      "metadata": {
        "id": "wyErbw6NkPrZ"
      },
      "id": "wyErbw6NkPrZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot training history (loss & accuracy)"
      ],
      "metadata": {
        "id": "WhCvVI-_lD5_"
      },
      "id": "WhCvVI-_lD5_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history: loss & accuracy\n",
        "history_dict = history.history\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history_dict[\"loss\"], label=\"train\")\n",
        "plt.plot(history_dict[\"val_loss\"], label=\"val\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training & validation loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history_dict[\"accuracy\"], label=\"train\")\n",
        "plt.plot(history_dict[\"val_accuracy\"], label=\"val\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training & validation accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Clt04e7lCnM"
      },
      "id": "-Clt04e7lCnM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions on the standard test set"
      ],
      "metadata": {
        "id": "CwwjFWmSlK6Z"
      },
      "id": "CwwjFWmSlK6Z"
    },
    {
      "cell_type": "code",
      "source": [
        "y_proba_test = model.predict(X_test_std)\n",
        "y_pred_test = np.argmax(y_proba_test, axis=1)\n",
        "\n",
        "print(\"Test accuracy (overall):\", np.mean(y_pred_test == y_test_std))"
      ],
      "metadata": {
        "id": "a94hHlYjlLW4"
      },
      "id": "a94hHlYjlLW4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute ROC curves (one-vs-rest) on the standard test set"
      ],
      "metadata": {
        "id": "7RlECL6Fl75d"
      },
      "id": "7RlECL6Fl75d"
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(y_test_std)\n",
        "plt.figure(figsize=(7,6))\n",
        "\n",
        "for c in classes:\n",
        "    # binary labels: 1 if this class, 0 otherwise\n",
        "    y_true_c = (y_test_std == c).astype(int)\n",
        "    y_score_c = y_proba_test[:, c]\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_true_c, y_score_c)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    original_label = inv_label_map[int(c)]\n",
        "    label_name = class_names[original_label]\n",
        "    plt.plot(fpr, tpr, lw=1.5, label=f\"class {original_label} ({label_name}) AUC={roc_auc:.3f}\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
        "plt.title(\"One-vs-rest ROC curves (standard test set)\")\n",
        "plt.legend(fontsize=7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zToaiB-kl6m8"
      },
      "id": "zToaiB-kl6m8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute confusion matrix for standard test"
      ],
      "metadata": {
        "id": "pv3lF0JHmE-f"
      },
      "id": "pv3lF0JHmE-f"
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_std, y_pred_test)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
        "plt.title(\"Confusion matrix (standard test set)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7s10IIkcmF6j"
      },
      "id": "7s10IIkcmF6j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "12283832-c48c-47a5-9e64-8644ad0a4073",
      "metadata": {
        "id": "12283832-c48c-47a5-9e64-8644ad0a4073"
      },
      "source": [
        "## 3. Convolutional Autoencoder for anomaly detection\n",
        "\n",
        "Steps:\n",
        "- Train a convolutional autoencoder on **standard** train set only\n",
        "- Plot training history\n",
        "- Compute reconstruction loss (MSE) per image for:\n",
        "  - Standard test set\n",
        "  - Anomaly dataset (class 4)\n",
        "- Plot histograms of reconstruction losses\n",
        "- Use reconstruction loss as anomaly score and build ROC curve & confusion matrix (adapt provided code)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a convolutional autoencoder on standard train set only"
      ],
      "metadata": {
        "id": "a8JjnjWYwA0a"
      },
      "id": "a8JjnjWYwA0a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4794c063-c5a9-41d7-8955-53ccf03b14e9",
      "metadata": {
        "id": "4794c063-c5a9-41d7-8955-53ccf03b14e9"
      },
      "outputs": [],
      "source": [
        "def build_conv_autoencoder(input_shape=(64, 64, 3)):\n",
        "    # ----- Encoder (all conv, no Dense) -----\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)   # 64 -> 32\n",
        "\n",
        "    x = layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)   # 32 -> 16\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding=\"same\", name=\"latent\")(x)  # 16 -> 8\n",
        "\n",
        "    # ----- Decoder (mirror of encoder) -----\n",
        "    x = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(encoded)\n",
        "    x = layers.UpSampling2D((2, 2))(x)                   # 8 -> 16\n",
        "\n",
        "    x = layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)                   # 16 -> 32\n",
        "\n",
        "    x = layers.Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)                   # 32 -> 64\n",
        "\n",
        "    outputs = layers.Conv2D(\n",
        "        3, (3, 3),\n",
        "        padding=\"same\",\n",
        "        activation=\"sigmoid\",   # images in [0,1]\n",
        "        name=\"reconstruction\",\n",
        "    )(x)\n",
        "\n",
        "    autoencoder = keras.Model(inputs, outputs, name=\"conv_autoencoder_simple\")\n",
        "    autoencoder.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-3),\n",
        "        loss=\"mse\",\n",
        "    )\n",
        "    return autoencoder\n",
        "\n",
        "# Build model\n",
        "input_shape = X_train_std.shape[1:]  # (64, 64, 3)\n",
        "autoencoder = build_conv_autoencoder(input_shape)\n",
        "autoencoder.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot training history\n"
      ],
      "metadata": {
        "id": "m12aAmpHwFwc"
      },
      "id": "m12aAmpHwFwc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train autoencoder on *standard* train set only\n",
        "batch_size = 64\n",
        "epochs = 25\n",
        "\n",
        "ae_callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,\n",
        "        restore_best_weights=True,\n",
        "    )\n",
        "]\n",
        "\n",
        "history_ae = autoencoder.fit(\n",
        "    X_train_std, X_train_std,               # input == target\n",
        "    validation_data=(X_val_std, X_val_std),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=ae_callbacks,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Plot training history (loss only, since autoencoder has no accuracy)\n",
        "hist = history_ae.history\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(hist[\"loss\"], label=\"train\")\n",
        "plt.plot(hist[\"val_loss\"], label=\"val\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE loss\")\n",
        "plt.title(\"Autoencoder training & validation loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dYOkkBTQwpJj"
      },
      "id": "dYOkkBTQwpJj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute reconstruction loss (MSE) per image for:\n",
        "- Standard test set\n",
        "- Anomaly dataset (class 4)"
      ],
      "metadata": {
        "id": "4fWOITgSwJEu"
      },
      "id": "4fWOITgSwJEu"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruction on standard test set\n",
        "X_test_std_recon = autoencoder.predict(X_test_std, batch_size=64, verbose=1)\n",
        "recon_loss_std = np.mean(\n",
        "    np.square(X_test_std_recon - X_test_std),\n",
        "    axis=(1, 2, 3)\n",
        ")\n",
        "\n",
        "# Reconstruction on anomaly set (class 4) – note: never seen during training\n",
        "anom_recon = autoencoder.predict(anom_images, batch_size=64, verbose=1)\n",
        "recon_loss_anom = np.mean(\n",
        "    np.square(anom_recon - anom_images),\n",
        "    axis=(1, 2, 3)\n",
        ")\n",
        "\n",
        "print(\"Reconstruction loss (standard test):\")\n",
        "print(\"  mean =\", recon_loss_std.mean(), \"std =\", recon_loss_std.std())\n",
        "print(\"Reconstruction loss (anomaly):\")\n",
        "print(\"  mean =\", recon_loss_anom.mean(), \"std =\", recon_loss_anom.std())\n"
      ],
      "metadata": {
        "id": "ahApYcP8wv-o"
      },
      "id": "ahApYcP8wv-o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot histograms of reconstruction losses"
      ],
      "metadata": {
        "id": "r3WxwDmpwIiH"
      },
      "id": "r3WxwDmpwIiH"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.hist(recon_loss_std,  bins=50, alpha=0.6, label=\"Standard test\")\n",
        "plt.hist(recon_loss_anom, bins=50, alpha=0.6, label=\"Anomaly (class 4)\")\n",
        "plt.xlabel(\"Reconstruction MSE\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Reconstruction loss distributions\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l-JUq7ttxEHw"
      },
      "id": "l-JUq7ttxEHw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use reconstruction loss as anomaly score and build ROC curve & confusion matrix (adapt provided code)"
      ],
      "metadata": {
        "id": "gdFQiXEPwfX6"
      },
      "id": "gdFQiXEPwfX6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build labels and scores\n",
        "y_true_ae = np.concatenate([\n",
        "    np.zeros_like(recon_loss_std, dtype=int),   # 0 = standard\n",
        "    np.ones_like(recon_loss_anom, dtype=int),   # 1 = anomaly\n",
        "])\n",
        "scores_ae = np.concatenate([recon_loss_std, recon_loss_anom])\n",
        "\n",
        "# ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true_ae, scores_ae)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
        "plt.plot([0,1], [0,1], \"k--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate (Recall for anomaly)\")\n",
        "plt.title(\"ROC curve (anomaly detection via AE reconstruction error)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WzdxRdqTxElh"
      },
      "id": "WzdxRdqTxElh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose threshold using Youden's J statistic\n",
        "j_scores = tpr - fpr\n",
        "best_idx = np.argmax(j_scores)\n",
        "best_thresh = thresholds[best_idx]\n",
        "print(\"Best threshold (Youden's J):\", best_thresh)\n",
        "\n",
        "# Binary predictions: 1 = anomaly if recon loss >= threshold\n",
        "y_pred_ae = (scores_ae >= best_thresh).astype(int)\n",
        "\n",
        "cm_ae = confusion_matrix(y_true_ae, y_pred_ae)\n",
        "print(\"Confusion matrix (AE anomaly detection):\")\n",
        "print(cm_ae)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm_ae,\n",
        "    display_labels=[\"Standard\", \"Anomaly\"],\n",
        ")\n",
        "disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
        "plt.title(\"Confusion matrix (AE anomaly detection)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zlFL-ygLxUyt"
      },
      "id": "zlFL-ygLxUyt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "65e65481-9247-4f8a-b5c8-c1394656d9f3",
      "metadata": {
        "id": "65e65481-9247-4f8a-b5c8-c1394656d9f3"
      },
      "source": [
        "## 4. Variational Autoencoder (VAE) on standard data\n",
        "\n",
        "Steps:\n",
        "- Build a VAE with convolutional encoder/decoder (trained on standard train set)\n",
        "- Plot training history\n",
        "- Generate new galaxy images from the VAE\n",
        "- Visualize some generated images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b06da04-33b4-4e0b-bd08-94f9aafaf3f0",
      "metadata": {
        "id": "4b06da04-33b4-4e0b-bd08-94f9aafaf3f0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}